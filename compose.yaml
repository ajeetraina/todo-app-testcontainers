services:
  server:
    build:
      context: .
      args:
        PROFILE: "default"
    ports:
      - 8080:8080
    depends_on:
      - db  # Ensure the database starts before the app
      - ollama
    environment:
      - 'POSTGRES_HOST=db'
      - 'POSTGRES_PORT=5432'
      - 'POSTGRES_USER=postgres'
      - 'POSTGRES_PASSWORD=postgres'  # Update with your actual password
      - 'POSTGRES_DB=postgres'  # Update with your database name
      - 'OLLAMA_API_BASE_URL=http://ollama:11434/api'
      - 'LANGCHAIN4J_OLLAMA_CHAT_MODEL_BASE_URL=http://ollama:11434/'
      - 'LANGCHAIN4J_OLLAMA_CHAT_MODEL_MODEL_NAME=llama3.2:3b'

  db:
    image: pgvector/pgvector:pg16
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres  # Update with your actual password
      POSTGRES_DB: postgres  # Update with your database name
    ports:
      - 5432:5432  # Expose the Postgres port
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  ollama:
    image: ilopezluna/llama3.2:0.3.12-3b # ollama with the model!
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    container_name: ollama
    volumes:
      - ollama:/root/.ollama
    ports:
      - 11434:11434
    tty: true
    environment:
      - 'OLLAMA_API_BASE_URL=http://ollama:11434/api'

volumes:
  ollama: { }